{
  "model_name": "CLIP-ViT-L-14",
  "model_description": "OpenAI CLIP model with ViT-L/14 backbone",
  "image_to_text": {
    "391895": ["12345", "12346", "12347", "12348", "12349", "12350", "12351", "12352", "12353", "12354"],
    "522418": ["23456", "23457", "23458", "23459", "23460", "23461", "23462", "23463", "23464", "23465"]
  },
  "text_to_image": {
    "12345": ["391895", "522418", "123456", "234567", "345678", "456789", "567890", "678901", "789012", "890123"],
    "23456": ["522418", "391895", "654321", "765432", "876543", "987654", "198765", "219876", "321987", "432198"]
  }
}
